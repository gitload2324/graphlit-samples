{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyNl3bO4BlU7nW36qcCBQfUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_09_08_Describe_Related_Images_from_Web_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to search the Web and ingest web pages, crawl image links, and describe the images. It also shows how to search the image descriptions based on the original Web search to find images related to your search text."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a1c855-8583-482a-c9db-3cf54e03cbf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlit-client in /usr/local/lib/python3.10/dist-packages (1.0.20240906001)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.8.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (13.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "# Create specification for OpenAI GPT-4o\n",
        "async def create_openai_specification():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=\"OpenAI GPT-4o\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            model=enums.OpenAIModels.GPT4O_128K,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "# Create specification for Anthropic Sonnet 3.5\n",
        "async def create_anthropic_specification():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=\"Anthropic Claude Sonnet 3.5\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.ANTHROPIC,\n",
        "        anthropic=input_types.AnthropicModelPropertiesInput(\n",
        "            model=enums.AnthropicModels.CLAUDE_3_5_SONNET,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "# Create enrichment workflow to crawl only image links from web pages, and enrich them with Groq Llava 1.5\n",
        "async def create_workflow(specification_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.WorkflowInput(\n",
        "        name=\"Link Crawling\",\n",
        "        extraction=input_types.ExtractionWorkflowStageInput(\n",
        "            jobs=[\n",
        "                input_types.ExtractionWorkflowJobInput(\n",
        "                    connector=input_types.EntityExtractionConnectorInput(\n",
        "                        type=enums.EntityExtractionServiceTypes.MODEL_IMAGE,\n",
        "                        modelImage=input_types.ModelImageExtractionPropertiesInput(\n",
        "                            specification=input_types.EntityReferenceInput(id=specification_id)\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "            ]\n",
        "        ),\n",
        "        enrichment=input_types.EnrichmentWorkflowStageInput(\n",
        "            link=input_types.LinkStrategyInput(\n",
        "                enableCrawling=True,\n",
        "                allowContentDomain=True,\n",
        "                allowedLinks=[enums.LinkTypes.FILE],\n",
        "                allowedFiles=[enums.FileTypes.IMAGE],\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_workflow(input)\n",
        "\n",
        "        return response.create_workflow.id if response.create_workflow is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_feed(search_text: str, read_limit: int, workflow_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.FeedInput(\n",
        "        name=\"Web Search\",\n",
        "        type=enums.FeedTypes.SEARCH,\n",
        "        search=input_types.SearchFeedPropertiesInput(\n",
        "            text=search_text,\n",
        "            readLimit=read_limit\n",
        "        ),\n",
        "        workflow=input_types.EntityReferenceInput(\n",
        "            id=workflow_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_feed(input)\n",
        "\n",
        "        return response.create_feed.id if response.create_feed is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def is_feed_done(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.is_feed_done(feed_id)\n",
        "\n",
        "    return response.is_feed_done.result if response.is_feed_done is not None else None\n",
        "\n",
        "# Locate images ingested by feed\n",
        "async def query_contents(feed_id: str, search: Optional[str] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_contents(\n",
        "            filter=input_types.ContentFilter(\n",
        "                search=search,\n",
        "                searchType=enums.SearchTypes.HYBRID,\n",
        "                fileTypes=[enums.FileTypes.IMAGE],\n",
        "                feeds=[\n",
        "                    input_types.EntityReferenceFilter(\n",
        "                        id=feed_id\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.contents.results if response.contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_workflows():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_workflows(is_synchronous=True)\n",
        "\n",
        "\n",
        "async def delete_all_feeds():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_feeds(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, Image\n",
        "import time\n",
        "\n",
        "# Remove any existing feeds and workflows; only needed for notebook example\n",
        "await delete_all_workflows()\n",
        "await delete_all_feeds()\n",
        "\n",
        "print('Deleted all feeds.')\n",
        "\n",
        "read_limit = 1 # how many search results to ingest from feed\n",
        "\n",
        "search_text = \"Seattle Kraken mascot Buoy\"\n",
        "\n",
        "# NOTE: uncomment just one of these to use different models\n",
        "specification_id = await create_anthropic_specification()\n",
        "#specification_id = await create_openai_specification()\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    workflow_id = await create_workflow(specification_id)\n",
        "\n",
        "    if workflow_id is not None:\n",
        "        print(f'Created workflow [{workflow_id}].')\n",
        "\n",
        "        feed_id = await create_feed(search_text, read_limit, workflow_id)\n",
        "\n",
        "        if feed_id is not None:\n",
        "            print(f'Created feed [{feed_id}].')\n",
        "\n",
        "            # Wait for feed to complete, since ingestion happens asychronously\n",
        "            done = False\n",
        "            time.sleep(5)\n",
        "            while not done:\n",
        "                done = await is_feed_done(feed_id)\n",
        "\n",
        "                if not done:\n",
        "                    time.sleep(2)\n",
        "\n",
        "            print(f'Completed feed [{feed_id}].')\n",
        "\n",
        "            # Show all the images crawled from the web page\n",
        "            contents = await query_contents(feed_id)\n",
        "\n",
        "            if contents is not None:\n",
        "                print(f'Found {len(contents)} images in feed [{feed_id}].')\n",
        "                print()\n",
        "\n",
        "                for content in contents:\n",
        "                    if content is not None and content.image is not None:\n",
        "                        display(Image(url=content.image_uri, width=256))\n",
        "\n",
        "            print()\n",
        "\n",
        "            # Show just the images related to the search text, and the image text and descriptions\n",
        "            contents = await query_contents(feed_id, search_text)\n",
        "\n",
        "            if contents is not None:\n",
        "                print(f'Found {len(contents)} images in feed [{feed_id}] related to [{search_text}].')\n",
        "                print()\n",
        "\n",
        "                for content in contents:\n",
        "                    if content is not None:\n",
        "                        display(Markdown(f'## {content.name} [{content.id}]:'))\n",
        "                        display(Markdown(f'Original image size: {content.image.width}x{content.image.height}'))\n",
        "\n",
        "                        if content.markdown is not None:\n",
        "                            display(Markdown(f'Text in image: {content.markdown}'))\n",
        "\n",
        "                        if content.image is not None:\n",
        "                            display(Image(url=content.image_uri, width=512))\n",
        "\n",
        "                            if content.image.description is not None:\n",
        "                                display(Markdown(f'### Description:\\n{content.image.description}'))"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c95d87e-fb5b-44b7-e30b-6d163b524d34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all feeds.\n",
            "Created specification [2cb2713a-e71b-476f-be81-cdd2240d948f].\n",
            "Created workflow [9ff18e57-9c1b-4989-b17a-423a283ead4c].\n",
            "Created feed [19dc2b0d-4ae3-4998-841a-489272fb2ac1].\n",
            "Completed feed [19dc2b0d-4ae3-4998-841a-489272fb2ac1].\n",
            "Found 15 images in feed [19dc2b0d-4ae3-4998-841a-489272fb2ac1].\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/c4ee8549-4e93-4118-8d9e-b0e859902641/Image/Coors_Light_mraqz8.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/2637e3cc-93a3-410e-b57c-7f6745b69762/Image/Starbucks_vjdmhs.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/875e90a2-e2a1-41a0-83e9-811cece31bdc/Image/Symetra_nsq9il.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/8830e314-fcef-4188-91ad-0c830d12123c/Image/Verizon_mrafto.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/0e86d2eb-8750-424b-8f3b-c7b928bea3ac/Image/MIT_Seal_1C-White_Hi_bqdyct.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/c2106ecf-6a3c-4c29-a1c4-caa3098fefa5/Image/WaFdBank_z1y4qf.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/92fecb86-3cd3-4f11-ba55-4d28fc90cd11/Image/VMFH_xoatcj.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/4ca06b53-3581-410c-be03-bd0fe13d0625/Image/Alaska_Airlines_new_au3rvf.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/37e05bf3-52d3-4bed-9f06-d0402794a0eb/Image/y9q8owblvg4aufryfthq.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/53b8f683-1c71-4339-b91a-a353cd6d269c/Image/cbt37l3okfcw5ptksnes.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/a0682f4e-e7cf-4131-b58c-146d7ca663ea/Image/ifttga66jgjxwb82fc58.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/e17a0c3a-a13a-41c0-9774-a7b746b64c51/Image/j4wxytjofvcditdhbalw.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/4a3a5c58-9243-4020-838e-cfde217a9527/Image/image_K_BuoyLogo_Color.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/ec5bcb84-8dde-45e6-bc0e-2d1bb9a25c19/Image/717229_tmpl_foot_5f7f92c716afb..jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/32fdccee-839c-4d54-95bf-b882791ad8a2/Image/zdvth9z8rgrd95atnj0j.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"256\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found 1 images in feed [19dc2b0d-4ae3-4998-841a-489272fb2ac1] related to [Seattle Kraken mascot Buoy].\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Starbucks_vjdmhs.png [2637e3cc-93a3-410e-b57c-7f6745b69762]:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Original image size: 841x96"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Text in image: "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://graphlit202409019591444c.blob.core.windows.net/files/2637e3cc-93a3-410e-b57c-7f6745b69762/Image/Starbucks_vjdmhs.jpg?sv=2024-08-04&se=2024-09-07T03%3A50%3A57Z&sr=c&sp=rl&sig=EmUY3kXrjGZv3w4NJ%2FRciirKB36Fv04ChvX7duCNaGM%3D\" width=\"512\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Description:\nBlog Post\n\nBlog Post\n\nBlog Post"
          },
          "metadata": {}
        }
      ]
    }
  ]
}