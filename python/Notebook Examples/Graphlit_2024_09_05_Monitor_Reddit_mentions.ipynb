{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyMMlT9qGEjNDSR2FhTrsxCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_09_05_Monitor_Reddit_mentions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to ingest a subReddit and monitor for company mentions."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fefizrrh4xGD"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "# Create entity extraction workflow, using Azure AI Text Analytics to identify organizations\n",
        "async def create_workflow():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.WorkflowInput(\n",
        "        name=\"Extraction\",\n",
        "        extraction=input_types.ExtractionWorkflowStageInput(\n",
        "            jobs=[\n",
        "                input_types.ExtractionWorkflowJobInput(\n",
        "                    connector=input_types.EntityExtractionConnectorInput(\n",
        "                        type=enums.EntityExtractionServiceTypes.AZURE_COGNITIVE_SERVICES_TEXT,\n",
        "                        extractedTypes=[enums.ObservableTypes.ORGANIZATION]\n",
        "                    )\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_workflow(input)\n",
        "\n",
        "        return response.create_workflow.id if response.create_workflow is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_feed(name: str, workflow_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.FeedInput(\n",
        "        name=name,\n",
        "        type=enums.FeedTypes.REDDIT,\n",
        "        reddit=input_types.RedditFeedPropertiesInput(\n",
        "            subredditName=name,\n",
        "            readLimit=50 # limiting to 50 Reddit posts\n",
        "        ),\n",
        "        workflow=input_types.EntityReferenceInput(\n",
        "            id=workflow_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_feed(input)\n",
        "\n",
        "        return response.create_feed.id if response.create_feed is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def is_feed_done(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.is_feed_done(feed_id)\n",
        "\n",
        "    return response.is_feed_done.result if response.is_feed_done is not None else None\n",
        "\n",
        "async def query_organizations(name: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_organizations(\n",
        "            filter=input_types.OrganizationFilter(\n",
        "                name=name\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.organizations.results if response.organizations is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "# Locate contents where organization was observed (by Azure AI Text Analytics)\n",
        "async def query_contents(organization_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_contents(\n",
        "            filter=input_types.ContentFilter(\n",
        "                observations=[\n",
        "                    input_types.ObservationReferenceFilter(\n",
        "                        type=enums.ObservableTypes.ORGANIZATION,\n",
        "                        observable=input_types.EntityReferenceFilter(\n",
        "                            id=organization_id\n",
        "                        )\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.contents.results if response.contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_workflows():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_workflows(is_synchronous=True)\n",
        "\n",
        "async def delete_all_feeds():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_feeds(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "import time\n",
        "\n",
        "# NOTE: Fill in the Reddit subreddit name\n",
        "subreddit_name = \"Anthropic\"\n",
        "\n",
        "# NOTE: Fill in the organization name you're looking for\n",
        "organization_name = \"Google\"\n",
        "\n",
        "# Remove any existing feeds and workflows; only needed for notebook example\n",
        "await delete_all_feeds()\n",
        "await delete_all_workflows()\n",
        "\n",
        "print('Deleted all feeds and workflows.')\n",
        "\n",
        "workflow_id = await create_workflow()\n",
        "\n",
        "if workflow_id is not None:\n",
        "    print(f'Created workflow [{workflow_id}].')\n",
        "\n",
        "    feed_id = await create_feed(name=subreddit_name, workflow_id=workflow_id)\n",
        "\n",
        "    if feed_id is not None:\n",
        "        print(f'Created feed [{feed_id}].')\n",
        "\n",
        "        # Wait for feed to complete, since ingestion happens asychronously\n",
        "        done = False\n",
        "        time.sleep(5)\n",
        "        while not done:\n",
        "            done = await is_feed_done(feed_id)\n",
        "\n",
        "            if not done:\n",
        "                time.sleep(2)\n",
        "\n",
        "        print(f'Completed feed [{feed_id}].')\n",
        "\n",
        "        organizations = await query_organizations(organization_name)\n",
        "\n",
        "        if organizations is not None and organizations.count != 0:\n",
        "            for organization in organizations:\n",
        "                if organization is not None:\n",
        "                    print(f'Found organization [{organization.id}] named [{organization.name}].')\n",
        "\n",
        "                    # Query contents by organization\n",
        "                    contents = await query_contents(organization.id)\n",
        "\n",
        "                    if contents is not None:\n",
        "                        for content in contents:\n",
        "                            if content is not None:\n",
        "                                display(Markdown(f'### Found Reddit post [{content.id}] that mentioned [{organization_name}]'))\n",
        "                                display(Markdown(content.markdown))\n",
        "                                print()\n",
        "        else:\n",
        "            print(f'No organizations named [{organization_name}] found.')"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}